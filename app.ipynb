{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy \n",
    "from spacy.lang.en.stop_words import STOP_WORDS\n",
    "from string import punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "text=\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp=spacy.load('en_core_web_sm')\n",
    "doc=nlp(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens= [token.text.lower() for token in doc\n",
    "         if not token.is_stop and\n",
    "         not token.is_punct and\n",
    "         token.text !='\\n']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens=[]\n",
    "stopwords =list(STOP_WORDS)\n",
    "alLowed_pos=['ADJ', 'PROPN' ,'VERB', 'NOUN']\n",
    "for token in doc:\n",
    "    if token.text in stopwords or token.text in punctuation:\n",
    "        continue\n",
    "    if token.pos_ in alLowed_pos:\n",
    "        tokens.append(token.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "from collections import Counter\n",
    "word_frequency = Counter(tokens)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_frequency=max(word_frequency.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "for word in word_frequency.keys():\n",
    "    word_frequency[word]=word_frequency[word]/max_frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "sent_token = [sent.text for sent in doc.sents]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence: hey sana, Score: 1.0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "sent_score = {}\n",
    "\n",
    "for sent in sent_token:\n",
    "    for word in sent.split():\n",
    "        if word.lower() in word_frequency.keys():\n",
    "            if sent not in sent_score.keys():\n",
    "                sent_score[sent] = word_frequency[word]\n",
    "            else:\n",
    "                sent_score[sent] += word_frequency[word]\n",
    "\n",
    "for sent, score in sent_score.items():\n",
    "    print(f\"Sentence: {sent}, Score: {score}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'hey sana': 1.0}"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>hey sana</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sentence  score\n",
       "0  hey sana    1.0"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "pd.DataFrame(list(sent_score.items()), columns=['sentence','score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'hey sana'"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from heapq import nlargest\n",
    "num_sentences=3\n",
    "n=nlargest(num_sentences, sent_score, key=sent_score.get)\n",
    "\"\".join(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "summarizer=pipeline(\"summarization\", model='t5-base', tokenizer='t5-base', framework='pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Your max_length is set to 100, but your input_length is only 9. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=4)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hey sana . hey sir .\n"
     ]
    }
   ],
   "source": [
    "summary=summarizer(text, max_length=100, min_length=10, do_sample=False)\n",
    "print(summary[0]['summary_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Your max_length is set to 100, but your input_length is only 58. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=29)\n"
     ]
    }
   ],
   "source": [
    "#GUI\n",
    "import tkinter as tk\n",
    "from transformers import pipeline\n",
    "\n",
    "summarizer = pipeline(\"summarization\", model='t5-base', tokenizer='t5-base', framework='pt')\n",
    "\n",
    "def summarize_text():\n",
    "    text = text_entry.get(\"1.0\", \"end-1c\")\n",
    "\n",
    "    summary = summarizer(text, max_length=100, min_length=10, do_sample=False)\n",
    "\n",
    "    output_text.delete(\"1.0\", \"end\")\n",
    "    output_text.insert(\"1.0\", summary[0]['summary_text'])\n",
    "\n",
    "window = tk.Tk()\n",
    "window.title(\"Text Summarizer\")\n",
    "\n",
    "text_entry = tk.Text(window, height=10, width=50)\n",
    "text_entry.pack()\n",
    "\n",
    "summarize_button = tk.Button(window, text=\"Summarize\", command=summarize_text)\n",
    "summarize_button.pack()\n",
    "\n",
    "output_text = tk.Text(window, height=10, width=50)\n",
    "output_text.pack()\n",
    "\n",
    "window.mainloop()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
